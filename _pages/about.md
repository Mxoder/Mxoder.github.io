---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

Authors marked with \* contributed equally (co-first authors).

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025</div><img src='images/Math-PUMA-500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning](https://ojs.aaai.org/index.php/AAAI/article/view/34815)

Wenwen Zhuang\*, Xin Huang\*, **Xiantao Zhang\***, Jin Zeng

[**Project**](https://github.com/wwzhuang01/Math-PUMA) <strong><span class='show_paper_citations' data='OpcS2vQAAAAJ:u5HHmVD_uO8C'></span></strong>
- This paper introduces Math-PUMA, a novel training methodology that uses Progressive Upward Multimodal Alignment to significantly narrow the performance gap between textual and visual modalities in mathematical reasoning , achieving state-of-the-art results among open-source MLLMs. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CV4A11y@ICCV 2025</div><img src='images/The_Escalator_Problem-500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)

**Xiantao Zhang**

[**Project**](https://arxiv.org/abs/2508.07989) <strong><span class='show_paper_citations' data='OpcS2vQAAAAJ:UeHWp8X0CEIC'></span></strong>
- This paper identifies "Implicit Motion Blindness" in MLLMs, exemplified by their failure to determine an escalator's direction , and argues this flaw‚Äîcaused by the prevalent frame-sampling paradigm ‚Äînecessitates a paradigm shift from semantic recognition to robust physical perception to build trustworthy assistive AI for the visually impaired. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">WCCA@ICCV 2025</div><img src='images/Pre_vs_Fab-500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Preservation vs. Fabrication: An Ethical Framework of Consent, Transparency, and Integrity for Posthumous AI Art](https://openreview.net/forum?id=UEHmz3m7zl)

**Xiantao Zhang**

[**Project**](https://openreview.net/forum?id=UEHmz3m7zl) <strong><span class='show_paper_citations' data='OpcS2vQAAAAJ:9yKSN-GCB0IC'></span></strong>
- This paper proposes an ethical framework for posthumous AI art, demanding the artist's explicit consent, mandatory transparency, and an integrity rule that forbids AI from fabricating new works where no verifiable intent exists. 
</div>
</div>



# üìñ Educations
- *2021.09 - 2025.06*, B.S. in Computer Science, School of Computer Science and Engineering (SCSE), Beihang University. 

# üéñ Honors and Awards

- *2025.06*, Outstanding Bachelor Thesis, School of Computer Science and Engineering (SCSE), Beihang University.

# üíª Internships
- *2024.07 - 2024.09*, ByteDance, Beijing.

# üìù Academic Service

- **Reviewer**, *ACL 2025* (ARR Feb. cycle) ‚Äî Recognized with **3 Great Review** awards
- **Reviewer**, *EMNLP 2025* (ARR May. cycle)
- **Reviewer**, *ACM Multimedia 2025*
- **Program Committee Member**, *AAAI 2026*
- **Reviewer**, *ICML 2025 Workshop on AIW*
- **Reviewer**, *NeurIPS 2025 Workshop on MATH-AI*
- **Reviewer**, *NeurIPS 2025 Workshop on COML*
- **Reviewer**, *COLM 2025 Workshop on INTERPLAY*
